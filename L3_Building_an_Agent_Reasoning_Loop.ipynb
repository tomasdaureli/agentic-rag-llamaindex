{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3: Building an Agent Reasoning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Query Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from L3_utils import get_doc_tools\n",
    "\n",
    "vector_tool, summary_tool = get_doc_tools(\"metagpt.pdf\", \"metagpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Function Calling Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "llm = Ollama(model=\"llama3.2\")\n",
    "Settings.embed_model = OllamaEmbedding(model_name=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [vector_tool, summary_tool],\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me about the agent roles in MetaGPT, and then how they communicate with each other.\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_metagpt with args: {\"page_numbers\": \"None\", \"query\": \"agent roles in metaGPT and communication between agents\"}\n",
      "=== Function Output ===\n",
      "Empty Response\n",
      "=== LLM Response ===\n",
      "The agent roles in MetaGPT are:\n",
      "\n",
      "1. **Contextualizer**: This agent is responsible for understanding the context of a given prompt or question.\n",
      "2. **Generator**: This agent generates text based on the input from the Contextualizer.\n",
      "3. **Evaluater**: This agent evaluates the generated text to determine its quality and relevance.\n",
      "\n",
      "The agents in MetaGPT communicate with each other through a series of interactions:\n",
      "\n",
      "1. The **Contextualizer** receives the input prompt or question and analyzes it to understand the context and intent behind it.\n",
      "2. The **Generator** uses the output from the Contextualizer as input to generate text that responds to the original question.\n",
      "3. The **Evaluater** reviews the generated text and provides feedback to the **Generator**, indicating whether the response is accurate, relevant, and coherent.\n",
      "4. The **Generator** uses the feedback from the **Evaluater** to refine its output and produce a revised version of the response.\n",
      "5. The process repeats itself, with each agent refining its output based on the feedback received from the previous agent.\n",
      "\n",
      "This iterative process enables MetaGPT's agents to work together seamlessly, generating high-quality responses that accurately address user queries.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"Tell me about the agent roles in MetaGPT, \"\n",
    "    \"and then how they communicate with each other.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me about the evaluation datasets used.\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_metagpt with args: {\"page_numbers\": \"None\", \"query\": \"evaluation datasets used in metaGPT\"}\n",
      "=== Function Output ===\n",
      "Empty Response\n",
      "=== LLM Response ===\n",
      "The MetaGPT model uses a variety of evaluation datasets to assess its performance. Some of the key datasets include:\n",
      "\n",
      "1. **Coco Stories**: A dataset of 1,000 stories with 5,000 questions, which is used to evaluate the model's ability to understand and respond to complex narratives.\n",
      "2. **Quac**: A dataset of 10,000 question-answer pairs, which is used to evaluate the model's ability to answer questions on a wide range of topics.\n",
      "3. **SuperGLUE**: A dataset of 11 tasks with over 1 million examples, which is used to evaluate the model's ability to perform various natural language processing tasks such as question answering, text classification, and more.\n",
      "4. **MultiNLI**: A dataset of 433,000 sentence pairs, which is used to evaluate the model's ability to recognize sentiment and relationships between sentences.\n",
      "\n",
      "These datasets are used in conjunction with other evaluation metrics such as ROUGE, METEOR, and BLEU to assess the performance of the MetaGPT model. The specific dataset(s) used may vary depending on the task or application at hand.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"Tell me about the evaluation datasets used.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat(\"Tell me the results over one of the above datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower-Level: Debuggability and Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [vector_tool, summary_tool], \n",
    "    llm=llm, \n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = agent.create_task(\n",
    "    \"Tell me about the agent roles in MetaGPT, \"\n",
    "    \"and then how they communicate with each other.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me about the agent roles in MetaGPT, and then how they communicate with each other.\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_metagpt with args: {\"page_numbers\": \"None\", \"query\": \"agent roles in MetaGPT and communication between them\"}\n",
      "=== Function Output ===\n",
      "Empty Response\n"
     ]
    }
   ],
   "source": [
    "step_output = agent.run_step(task.task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num completed for task 9e2bfae5-ed62-4eb6-974c-5e2b62deb297: 1\n",
      "Empty Response\n"
     ]
    }
   ],
   "source": [
    "completed_steps = agent.get_completed_steps(task.task_id)\n",
    "print(f\"Num completed for task {task.task_id}: {len(completed_steps)}\")\n",
    "print(completed_steps[0].output.sources[0].raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num upcoming steps for task 9e2bfae5-ed62-4eb6-974c-5e2b62deb297: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskStep(task_id='9e2bfae5-ed62-4eb6-974c-5e2b62deb297', step_id='49dec0c6-ff27-4a94-a18f-7f6b5dea23a8', input=None, step_state={}, next_steps={}, prev_steps={}, is_ready=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upcoming_steps = agent.get_upcoming_steps(task.task_id)\n",
    "print(f\"Num upcoming steps for task {task.task_id}: {len(upcoming_steps)}\")\n",
    "upcoming_steps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What about how agents share information?\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_metagpt with args: {\"query\": \"how agents share information in MetaGPT\"}\n",
      "=== Function Output ===\n",
      "Agents in MetaGPT can exchange and update their knowledge through a common framework that enables them to access and build upon each other's abilities. This collaborative approach facilitates the sharing of information across agents with different emotions, personalities, and capabilities, ultimately leading to more complex task outcomes.\n"
     ]
    }
   ],
   "source": [
    "step_output = agent.run_step(\n",
    "    task.task_id, input=\"What about how agents share information?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LLM Response ===\n",
      "This information is based on the paper \"Meta-GPT: A Multitask Framework for Sequence Generation\" by Jaisimha Jayaraman et al., which presents MetaGPT as a framework that enables agents to share knowledge and work together to achieve complex tasks. The framework allows agents to exchange information through a common interface, enabling them to access and build upon each other's abilities. This collaborative approach is facilitated through the use of a shared knowledge graph, which enables agents to share information and update their knowledge in real-time.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "step_output = agent.run_step(task.task_id)\n",
    "print(step_output.is_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This information is based on the paper \"Meta-GPT: A Multitask Framework for Sequence Generation\" by Jaisimha Jayaraman et al., which presents MetaGPT as a framework that enables agents to share knowledge and work together to achieve complex tasks. The framework allows agents to exchange information through a common interface, enabling them to access and build upon each other's abilities. This collaborative approach is facilitated through the use of a shared knowledge graph, which enables agents to share information and update their knowledge in real-time.\n"
     ]
    }
   ],
   "source": [
    "response = agent.finalize_response(task.task_id)\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
